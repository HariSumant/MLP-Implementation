{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch: Neural Network-Feedforward/MLP.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPLhqp4RG4+SrcnqKcDks8e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HariSumant/MLP-Implementation/blob/main/PyTorch_Neural_Network_Feedforward_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part One\n"
      ],
      "metadata": {
        "id": "KaPd2Ei2T1mU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mC_pZLVzVhzN",
        "outputId": "9961c949-d0d7-4b86-ad34-f0962e6515ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "x = torch.ones(1, requires_grad=True)\n",
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.ones(1, requires_grad=True)\n",
        "y = x + 2\n",
        "z = y * y * 2\n",
        "\n",
        "z.backward()\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiqophFYVkga",
        "outputId": "4608e9f1-d12d-40d4-da8d-46864c843f88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([12.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn \n",
        "\n",
        "class Perceptron(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Perceptron, self).__init__()\n",
        "        self.fc = nn.Linear(1,1)\n",
        "        self.relu = torch.nn.ReLU() # instead of Heaviside step fn\n",
        "    def forward(self, x):\n",
        "        output = self.fc(x)\n",
        "        output = self.relu(x) # instead of Heaviside step fn\n",
        "        return output"
      ],
      "metadata": {
        "id": "yEGDKNsSVkd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Feedforward(torch.nn.Module):\n",
        "        def __init__(self, input_size, hidden_size):\n",
        "            super(Feedforward, self).__init__()\n",
        "            self.input_size = input_size\n",
        "            self.hidden_size  = hidden_size\n",
        "            self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
        "            self.relu = torch.nn.ReLU()\n",
        "            self.fc2 = torch.nn.Linear(self.hidden_size, 1)\n",
        "            self.sigmoid = torch.nn.Sigmoid()\n",
        "        def forward(self, x):\n",
        "            hidden = self.fc1(x)\n",
        "            relu = self.relu(hidden)\n",
        "            output = self.fc2(relu)\n",
        "            output = self.sigmoid(output)\n",
        "            return output"
      ],
      "metadata": {
        "id": "Rr7EM-uqaDpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATE RANDOM DATA POINTS\n",
        "from sklearn.datasets import make_blobs\n",
        "import numpy\n",
        "\n",
        "def blob_label(y, label, loc): # assign labels\n",
        "    target = numpy.copy(y)\n",
        "    for l in loc:\n",
        "        target[y == l] = label\n",
        "    return target\n",
        "x_train, y_train = make_blobs(n_samples=40, n_features=2, cluster_std=1.5, shuffle=True)\n",
        "x_train = torch.FloatTensor(x_train)\n",
        "y_train = torch.FloatTensor(blob_label(y_train, 0, [0]))\n",
        "y_train = torch.FloatTensor(blob_label(y_train, 1, [1,2,3]))\n",
        "x_test, y_test = make_blobs(n_samples=10, n_features=2, cluster_std=1.5, shuffle=True)\n",
        "x_test = torch.FloatTensor(x_test)\n",
        "y_test = torch.FloatTensor(blob_label(y_test, 0, [0]))\n",
        "y_test = torch.FloatTensor(blob_label(y_test, 1, [1,2,3]))"
      ],
      "metadata": {
        "id": "KhnxSNr5aDmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Feedforward(2, 10)\n",
        "criterion = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)"
      ],
      "metadata": {
        "id": "2_dwbLg4eSIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "y_pred = model(x_test)\n",
        "before_train = criterion(y_pred.squeeze(), y_test)\n",
        "print('Test loss before training' , before_train.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoqpObdxeSGB",
        "outputId": "e30eecfd-e22f-49c5-c436-5e33c9de3a53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss before training 1.289565086364746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "epoch = 20\n",
        "for epoch in range(epoch):\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    y_pred = model(x_train)\n",
        "    # Compute Loss\n",
        "    loss = criterion(y_pred.squeeze(), y_train)\n",
        "   \n",
        "    print('Epoch {}: train loss: {}'.format(epoch, loss.item()))\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cg_45NADeSDb",
        "outputId": "9d4b7125-b4dc-4145-b2ec-2bdb3ca93bbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: train loss: 0.773210346698761\n",
            "Epoch 1: train loss: 0.7594887614250183\n",
            "Epoch 2: train loss: 0.7469272613525391\n",
            "Epoch 3: train loss: 0.7354226112365723\n",
            "Epoch 4: train loss: 0.724882960319519\n",
            "Epoch 5: train loss: 0.7152196168899536\n",
            "Epoch 6: train loss: 0.7063432335853577\n",
            "Epoch 7: train loss: 0.6981762647628784\n",
            "Epoch 8: train loss: 0.6906481981277466\n",
            "Epoch 9: train loss: 0.6836941242218018\n",
            "Epoch 10: train loss: 0.677256166934967\n",
            "Epoch 11: train loss: 0.671284019947052\n",
            "Epoch 12: train loss: 0.6657263040542603\n",
            "Epoch 13: train loss: 0.6605402231216431\n",
            "Epoch 14: train loss: 0.6556877493858337\n",
            "Epoch 15: train loss: 0.6511346697807312\n",
            "Epoch 16: train loss: 0.6468503475189209\n",
            "Epoch 17: train loss: 0.6428077816963196\n",
            "Epoch 18: train loss: 0.6389827132225037\n",
            "Epoch 19: train loss: 0.6353538036346436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "y_pred = model(x_test)\n",
        "after_train = criterion(y_pred.squeeze(), y_test) \n",
        "print('Test loss after Training' , after_train.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2iyWeixeSAs",
        "outputId": "d38cafcb-9c64-4e37-c58b-404202d523da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss after Training 1.2130515575408936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RiQ8kk6heqHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZkOjwkQqeqE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part Two\n"
      ],
      "metadata": {
        "id": "iuSI5hdjUr8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "kZaRMbfrUzkC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Feedforward(torch.nn.Module):\n",
        "        def __init__(self, input_size, hidden_size):\n",
        "            super(Feedforward, self).__init__()\n",
        "            self.input_size = input_size\n",
        "            self.hidden_size  = hidden_size\n",
        "            self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
        "            self.relu = torch.nn.ReLU()\n",
        "            self.fc2 = torch.nn.Linear(self.hidden_size, 1)\n",
        "            self.sigmoid = torch.nn.Sigmoid()\n",
        "        def forward(self, x):\n",
        "            hidden = self.fc1(x)\n",
        "            relu = self.relu(hidden)\n",
        "            output = self.fc2(relu)\n",
        "            output = self.sigmoid(output)\n",
        "            return output"
      ],
      "metadata": {
        "id": "ButHda7fU1T5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "import numpy\n",
        "\n",
        "def blob_label(y, label, loc): # assign labels\n",
        "    target = numpy.copy(y)\n",
        "    for l in loc:\n",
        "        target[y == l] = label\n",
        "    return target\n",
        "x_train, y_train = make_blobs(n_samples=40, n_features=2, cluster_std=1.5, shuffle=True)\n",
        "x_train = torch.FloatTensor(x_train)\n",
        "y_train = torch.FloatTensor(blob_label(y_train, 0, [0]))\n",
        "y_train = torch.FloatTensor(blob_label(y_train, 1, [1,2,3]))\n",
        "x_test, y_test = make_blobs(n_samples=10, n_features=2, cluster_std=1.5, shuffle=True)\n",
        "x_test = torch.FloatTensor(x_test)\n",
        "y_test = torch.FloatTensor(blob_label(y_test, 0, [0]))\n",
        "y_test = torch.FloatTensor(blob_label(y_test, 1, [1,2,3]))"
      ],
      "metadata": {
        "id": "DjCpqPKoU1RB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Feedforward(2, 10)\n",
        "criterion = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)"
      ],
      "metadata": {
        "id": "5jqRQq5eV9ht"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "y_pred = model(x_test)\n",
        "before_train = criterion(y_pred.squeeze(), y_test)\n",
        "print('Test loss before training' , before_train.item())"
      ],
      "metadata": {
        "id": "s59ykbc8V9fB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "epoch = 20\n",
        "for epoch in range(epoch):\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    y_pred = model(x_train)\n",
        "    # Compute Loss\n",
        "    loss = criterion(y_pred.squeeze(), y_train)\n",
        "   \n",
        "    print('Epoch {}: train loss: {}'.format(epoch, loss.item()))\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "CENG8oJSWHq7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db92e3c3-70e0-4c95-c2c5-de83f00c45b9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: train loss: 0.702000617980957\n",
            "Epoch 1: train loss: 0.6673703193664551\n",
            "Epoch 2: train loss: 0.6392861604690552\n",
            "Epoch 3: train loss: 0.6163275837898254\n",
            "Epoch 4: train loss: 0.5973542928695679\n",
            "Epoch 5: train loss: 0.5814792513847351\n",
            "Epoch 6: train loss: 0.5680240988731384\n",
            "Epoch 7: train loss: 0.5564731359481812\n",
            "Epoch 8: train loss: 0.5464335680007935\n",
            "Epoch 9: train loss: 0.5376052856445312\n",
            "Epoch 10: train loss: 0.5297567248344421\n",
            "Epoch 11: train loss: 0.5227082371711731\n",
            "Epoch 12: train loss: 0.5163189172744751\n",
            "Epoch 13: train loss: 0.5104768872261047\n",
            "Epoch 14: train loss: 0.5050930976867676\n",
            "Epoch 15: train loss: 0.5000431537628174\n",
            "Epoch 16: train loss: 0.49524742364883423\n",
            "Epoch 17: train loss: 0.49072790145874023\n",
            "Epoch 18: train loss: 0.4864446520805359\n",
            "Epoch 19: train loss: 0.4823647439479828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "y_pred = model(x_test)\n",
        "after_train = criterion(y_pred.squeeze(), y_test) \n",
        "print('Test loss after Training' , after_train.item())"
      ],
      "metadata": {
        "id": "tr_SraPiWHoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "elIwNsm-WLqK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}